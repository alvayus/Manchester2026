{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da23be40",
   "metadata": {},
   "source": [
    "# Cascade NAS Tutorial: Neuromorphic Auditory Processing with OKAERTool\n",
    "\n",
    "This notebook provides a comprehensive tutorial on using the **Cascade Neuromorphic Auditory Sensor (NAS)** with the **OKAERTool** platform. You will learn how to configure, monitor, and analyze spike events from a bio-inspired auditory sensor deployed on FPGA hardware.\n",
    "\n",
    "## What is the Cascade NAS?\n",
    "\n",
    "The Cascade NAS is a neuromorphic auditory sensor that mimics the structure and function of the biological cochlea. It processes audio signals in real-time and outputs Address-Event Representation (AER) spike streams. The cascade architecture features:\n",
    "\n",
    "- **64 frequency channels** arranged in a cascade topology\n",
    "- **Bio-inspired bandpass filtering** mimicking cochlear mechanics\n",
    "- **Spike-based output** for efficient neuromorphic processing\n",
    "- **Real-time operation** suitable for edge computing applications\n",
    "\n",
    "## What is OKAERTool?\n",
    "\n",
    "**OKAERTool** ([https://github.com/RTC-research-group/okaertool](https://github.com/RTC-research-group/okaertool)) is an open-source hardware platform designed for deploying and testing AER-based neuromorphic systems on FPGA. It provides:\n",
    "\n",
    "- **Hardware IP blocks** for AER event management\n",
    "- **Python interface (pyOKAERTool)** for easy configuration and monitoring\n",
    "- **Integration with pyNAVIS** for spike visualization\n",
    "- **Support for multiple neuromorphic sensors** including NAS\n",
    "\n",
    "This tutorial will guide you through the complete workflow from initialization to advanced event analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d2471",
   "metadata": {},
   "source": [
    "## 1. Import Required Packages and Initialize OKAERTool\n",
    "\n",
    "First, we need to import the necessary libraries and initialize the OKAERTool hardware platform. We'll also configure the pyNAVIS settings for spike visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb611525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add repository root to sys.path for importing pyOKAERTool\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if os.path.isdir(os.path.join(repo_root, 'pyOKAERTool')) and repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "else:\n",
    "    # Fallback: walk up parent directories to find pyOKAERTool\n",
    "    p = os.path.abspath(os.getcwd())\n",
    "    for _ in range(4):\n",
    "        if os.path.isdir(os.path.join(p, 'pyOKAERTool')):\n",
    "            if p not in sys.path:\n",
    "                sys.path.insert(0, p)\n",
    "            break\n",
    "        p = os.path.dirname(p)\n",
    "\n",
    "import pyOKAERTool as okt\n",
    "from pyNAVIS import *\n",
    "import numpy as np\n",
    "\n",
    "# Define bitfile path for the FPGA configuration\n",
    "bitfile_path = '../../bitfiles/CNAS_okaertool_XEM6310_config_0_rst.bit'\n",
    "\n",
    "# Validate bitfile existence\n",
    "if bitfile_path is not None and not os.path.exists(bitfile_path):\n",
    "    print(f\"ERROR: Bitfile not found at: {bitfile_path}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Create and initialize OKAERTool instance\n",
    "print(\"Initializing OKAERTool...\")\n",
    "okaer = okt.Okaertool(bit_file=bitfile_path)\n",
    "okaer.init()\n",
    "print(\"✓ OKAERTool initialized successfully\")\n",
    "\n",
    "# Configure pyNAVIS settings for visualization\n",
    "# Parameters:\n",
    "#   - num_channels: 64 frequency channels in the Cascade NAS\n",
    "#   - mono_stereo: 1 for stereo (left/right cochlea)\n",
    "#   - on_off_both: 1 for both ON and OFF events\n",
    "#   - address_size: 4 bytes for address representation\n",
    "#   - ts_tick: 0.01 ms timestamp resolution\n",
    "#   - bin_size: 10000 for histogram binning\n",
    "settings = MainSettings(\n",
    "    num_channels=64, \n",
    "    mono_stereo=1, \n",
    "    on_off_both=1, \n",
    "    address_size=4, \n",
    "    ts_tick=0.01, \n",
    "    bin_size=10000\n",
    ")\n",
    "print(\"✓ PyNAVIS settings configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8540cb",
   "metadata": {},
   "source": [
    "## 2. Define Configuration Parameters\n",
    "\n",
    "The Cascade NAS requires specific configuration parameters to operate correctly. These parameters control both the digital audio interface and the cochlear filter bank characteristics.\n",
    "\n",
    "### I2S2Spikes Parameters\n",
    "\n",
    "The **I2S2Spikes** module converts digital I2S audio signals into spike events. The parameter controls the sensitivity and thresholding behavior.\n",
    "\n",
    "### CASCADE_FILTER Parameters\n",
    "\n",
    "Each of the 64 cochlear channels requires 4 configuration parameters:\n",
    "\n",
    "1. **FREQ_DIV** - Frequency divider determining the center frequency of the channel\n",
    "2. **SPIKES_DIV_FB** - Spike divider for the feedback path (controls resonance)\n",
    "3. **SPIKES_DIV_OUT** - Spike divider for the output (controls firing rate)\n",
    "4. **SPIKES_DIV_BPF** - Spike divider for the bandpass filter (controls bandwidth)\n",
    "\n",
    "These parameters define the frequency selectivity and temporal dynamics of each cochlear filter, arranged from high to low frequencies to mimic biological cochlear organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I2S2Spikes configuration parameter\n",
    "# Controls the digital audio interface conversion to spikes\n",
    "I2S2Spikes_DEFAULT_parameter = [0x000F]\n",
    "\n",
    "# CASCADE_FILTER configuration parameters\n",
    "# 64 filters × 4 parameters = 256 values\n",
    "# Each group of 4 values configures one cochlear channel\n",
    "CASCADE_FILTER_DEFAULT_parameter = [\n",
    "    # Filter 1 (highest frequency)\n",
    "    0x04, 0x77B4, 0x77B4, 0x2025, \n",
    "    # Filter 2\n",
    "    0x04, 0x6B1C, 0x6B1C, 0x2025,\n",
    "    # Filter 3\n",
    "    0x02, 0x7303, 0x7303, 0x2025, \n",
    "    # Filter 4\n",
    "    0x02, 0x66E9, 0x66E9, 0x2025, \n",
    "    # Filter 5\n",
    "    0x03, 0x7AC8, 0x7AC8, 0x2025, \n",
    "    # Filter 6\n",
    "    0x03, 0x6DDD, 0x6DDD, 0x2025, \n",
    "    # Filter 7\n",
    "    0x04, 0x7AE1, 0x7AE1, 0x2025, \n",
    "    # Filter 8\n",
    "    0x04, 0x6DF4, 0x6DF4, 0x2025, \n",
    "    # Filter 9\n",
    "    0x02, 0x7610, 0x7610, 0x2025, \n",
    "    # Filter 10\n",
    "    0x02, 0x69A4, 0x69A4, 0x2025, \n",
    "    # Filter 11\n",
    "    0x03, 0x7E0A, 0x7E0A, 0x2025, \n",
    "    # Filter 12\n",
    "    0x03, 0x70C7, 0x70C7, 0x2025, \n",
    "    # Filter 13\n",
    "    0x04, 0x7E24, 0x7E24, 0x2025, \n",
    "    # Filter 14\n",
    "    0x04, 0x70DF, 0x70DF, 0x2025, \n",
    "    # Filter 15\n",
    "    0x02, 0x7932, 0x7932, 0x2025, \n",
    "    # Filter 16\n",
    "    0x02, 0x6C72, 0x6C72, 0x2025, \n",
    "    # Filter 17\n",
    "    0x02, 0x6109, 0x6109, 0x2025, \n",
    "    # Filter 18\n",
    "    0x03, 0x73C5, 0x73C5, 0x2025, \n",
    "    # Filter 19\n",
    "    0x03, 0x6797, 0x6797, 0x2025, \n",
    "    # Filter 20\n",
    "    0x04, 0x73DD, 0x73DD, 0x2025, \n",
    "    # Filter 21\n",
    "    0x02, 0x7C69, 0x7C69, 0x2025, \n",
    "    # Filter 22\n",
    "    0x02, 0x6F52, 0x6F52, 0x2025, \n",
    "    # Filter 23\n",
    "    0x02, 0x639C, 0x639C, 0x2025, \n",
    "    # Filter 24\n",
    "    0x03, 0x76D8, 0x76D8, 0x2025, \n",
    "    # Filter 25\n",
    "    0x03, 0x6A57, 0x6A57, 0x2025, \n",
    "    # Filter 26\n",
    "    0x04, 0x76F1, 0x76F1, 0x2025, \n",
    "    # Filter 27\n",
    "    0x02, 0x7FB6, 0x7FB6, 0x2025, \n",
    "    # Filter 28\n",
    "    0x02, 0x7247, 0x7247, 0x2025, \n",
    "    # Filter 29\n",
    "    0x02, 0x6641, 0x6641, 0x2025, \n",
    "    # Filter 30\n",
    "    0x03, 0x79FF, 0x79FF, 0x2025, \n",
    "    # Filter 31\n",
    "    0x03, 0x6D29, 0x6D29, 0x2025, \n",
    "    # Filter 32\n",
    "    0x04, 0x7A19, 0x7A19, 0x2025, \n",
    "    # Filter 33 (middle frequencies)\n",
    "    0x04, 0x6D40, 0x6D40, 0x2025, \n",
    "    # Filter 34\n",
    "    0x02, 0x754F, 0x754F, 0x2025, \n",
    "    # Filter 35\n",
    "    0x02, 0x68F7, 0x68F7, 0x2025, \n",
    "    # Filter 36\n",
    "    0x03, 0x7D3C, 0x7D3C, 0x2025, \n",
    "    # Filter 37\n",
    "    0x03, 0x700F, 0x700F, 0x2025, \n",
    "    # Filter 38\n",
    "    0x04, 0x7D56, 0x7D56, 0x2025, \n",
    "    # Filter 39\n",
    "    0x04, 0x7026, 0x7026, 0x2025, \n",
    "    # Filter 40\n",
    "    0x02, 0x786C, 0x786C, 0x2025, \n",
    "    # Filter 41\n",
    "    0x02, 0x6BC1, 0x6BC1, 0x2025, \n",
    "    # Filter 42\n",
    "    0x02, 0x606A, 0x606A, 0x2025, \n",
    "    # Filter 43\n",
    "    0x03, 0x7308, 0x7308, 0x2025, \n",
    "    # Filter 44\n",
    "    0x03, 0x66EE, 0x66EE, 0x2025, \n",
    "    # Filter 45\n",
    "    0x04, 0x7320, 0x7320, 0x2025, \n",
    "    # Filter 46\n",
    "    0x02, 0x7B9E, 0x7B9E, 0x2025, \n",
    "    # Filter 47\n",
    "    0x02, 0x6E9C, 0x6E9C, 0x2025, \n",
    "    # Filter 48\n",
    "    0x02, 0x62F9, 0x62F9, 0x2025, \n",
    "    # Filter 49\n",
    "    0x03, 0x7615, 0x7615, 0x2025, \n",
    "    # Filter 50\n",
    "    0x03, 0x69A9, 0x69A9, 0x2025, \n",
    "    # Filter 51\n",
    "    0x04, 0x762E, 0x762E, 0x2025, \n",
    "    # Filter 52\n",
    "    0x02, 0x7EE6, 0x7EE6, 0x2025, \n",
    "    # Filter 53\n",
    "    0x02, 0x718C, 0x718C, 0x2025, \n",
    "    # Filter 54\n",
    "    0x02, 0x659A, 0x659A, 0x2025, \n",
    "    # Filter 55\n",
    "    0x03, 0x7937, 0x7937, 0x2025, \n",
    "    # Filter 56\n",
    "    0x03, 0x6C77, 0x6C77, 0x2025, \n",
    "    # Filter 57\n",
    "    0x04, 0x7951, 0x7951, 0x2025, \n",
    "    # Filter 58\n",
    "    0x04, 0x6C8E, 0x6C8E, 0x2025, \n",
    "    # Filter 59\n",
    "    0x02, 0x748F, 0x748F, 0x2025, \n",
    "    # Filter 60\n",
    "    0x02, 0x684C, 0x684C, 0x2025, \n",
    "    # Filter 61\n",
    "    0x03, 0x7C6F, 0x7C6F, 0x2025, \n",
    "    # Filter 62\n",
    "    0x03, 0x6F57, 0x6F57, 0x2025,\n",
    "    # Filter 63\n",
    "    0x04, 0x7C89, 0x7C89, 0x2025, \n",
    "    # Filter 64 (lowest frequency)\n",
    "    0x04, 0x6F6F, 0x6F6F, 0x2025, \n",
    "    0x02, 0x77A7, 0x77A7, 0x2025\n",
    "]\n",
    "\n",
    "print(f\"Configuration parameters loaded:\")\n",
    "print(f\"  - I2S2Spikes: {len(I2S2Spikes_DEFAULT_parameter)} parameters\")\n",
    "print(f\"  - CASCADE_FILTER: {len(CASCADE_FILTER_DEFAULT_parameter)} parameters ({len(CASCADE_FILTER_DEFAULT_parameter)//4} filters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6579bccd",
   "metadata": {},
   "source": [
    "## 3. Configure the Cascade NAS\n",
    "\n",
    "Now we'll program the FPGA with our configuration parameters. This involves:\n",
    "\n",
    "1. **Resetting the board** to ensure a clean state\n",
    "2. **Configuring I2S2Spikes** module for audio signal conversion\n",
    "3. **Configuring left cochlea** cascade filters (64 channels)\n",
    "4. **Configuring right cochlea** cascade filters (64 channels)\n",
    "\n",
    "Each configuration writes parameter values to specific register addresses in the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5735530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the OKAERTool board\n",
    "print(\"Resetting OKAERTool board...\")\n",
    "okaer.reset_board()\n",
    "print(\"✓ Board reset complete\")\n",
    "\n",
    "# Configure I2S2Spikes module\n",
    "# Register address: 0x08\n",
    "register_address = 0x08\n",
    "okaer.logger.info(\"Configuring I2S2Spikes module\")\n",
    "for value in I2S2Spikes_DEFAULT_parameter:\n",
    "    okaer.set_config('port_a', register_address, value)\n",
    "print(\"✓ I2S2Spikes configured\")\n",
    "\n",
    "# Configure CASCADE filters for LEFT cochlea\n",
    "# Starting register address: 0x09\n",
    "register_address = 0x09\n",
    "okaer.logger.info(\"Configuring LEFT cochlea cascade filters\")\n",
    "for value in CASCADE_FILTER_DEFAULT_parameter:\n",
    "    okaer.set_config('port_a', register_address, value)\n",
    "    register_address += 1\n",
    "print(f\"✓ Left cochlea configured (64 filters)\")\n",
    "\n",
    "# Configure CASCADE filters for RIGHT cochlea\n",
    "# Starting register address: 0x010D (269 in decimal)\n",
    "register_address = 0x010D\n",
    "okaer.logger.info(\"Configuring RIGHT cochlea cascade filters\")\n",
    "for value in CASCADE_FILTER_DEFAULT_parameter:\n",
    "    okaer.set_config('port_a', register_address, value)\n",
    "    register_address += 1\n",
    "print(f\"✓ Right cochlea configured (64 filters)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CASCADE NAS CONFIGURATION COMPLETE\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93d60a",
   "metadata": {},
   "source": [
    "## 4. Monitor NAS Output Events\n",
    "\n",
    "The OKAERTool provides flexible monitoring capabilities for capturing spike events from the NAS. You can monitor events based on:\n",
    "\n",
    "- **Duration**: Capture events for a specific time period (e.g., 0.5 seconds)\n",
    "- **Spike count**: Capture until a maximum number of spikes is reached\n",
    "- **Both constraints**: Stop when either condition is met\n",
    "\n",
    "Let's demonstrate all three monitoring modes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a665f",
   "metadata": {},
   "source": [
    "### 4.1 Monitor by Duration\n",
    "\n",
    "This is the most common monitoring mode - capture all events that occur during a specified time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitoring configuration\n",
    "MAX_INPUTS = 3  # Number of input channels to monitor\n",
    "INPUTS = ['port_a']  # Monitor port A (Cascade NAS)\n",
    "DURATION = 0.5  # Monitoring duration in seconds\n",
    "\n",
    "print(f\"Monitoring for {DURATION} seconds...\")\n",
    "print(\"Waiting for spike events...\")\n",
    "\n",
    "# Monitor for a specific duration\n",
    "spikes = okaer.monitor(inputs=INPUTS, duration=DURATION)\n",
    "\n",
    "# Validate that spikes were captured\n",
    "if spikes is None:\n",
    "    okaer.logger.error(\"No spikes were recorded. Check audio input!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Print spike count for each input\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MONITORING RESULTS (Duration mode)\")\n",
    "print(\"=\"*50)\n",
    "for i in range(MAX_INPUTS):\n",
    "    num_spikes = spikes[i].get_num_spikes()\n",
    "    print(f\"Input {i}: {num_spikes:,} spikes\")\n",
    "    if num_spikes > 0:\n",
    "        print(f\"  ├─ Spike rate: {num_spikes/DURATION:.1f} spikes/second\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75ce4b",
   "metadata": {},
   "source": [
    "### 4.2 Monitor by Spike Count\n",
    "\n",
    "Capture events until a specific number of spikes is reached, useful when you need a fixed amount of data regardless of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad85e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SPIKES = 10000  # Maximum spikes to capture\n",
    "\n",
    "print(f\"Monitoring until {MAX_SPIKES:,} spikes are captured...\")\n",
    "print(\"Waiting for spike events...\")\n",
    "\n",
    "# Monitor for a specific number of spikes\n",
    "spikes_count_mode = okaer.monitor(inputs=INPUTS, max_spikes=MAX_SPIKES)\n",
    "\n",
    "if spikes_count_mode is None:\n",
    "    okaer.logger.error(\"No spikes were recorded.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MONITORING RESULTS (Spike count mode)\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(MAX_INPUTS):\n",
    "        num_spikes = spikes_count_mode[i].get_num_spikes()\n",
    "        print(f\"Input {i}: {num_spikes:,} spikes\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4e116",
   "metadata": {},
   "source": [
    "### 4.3 Monitor with Both Constraints\n",
    "\n",
    "Stop monitoring when EITHER the duration limit OR the spike count limit is reached - whichever comes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e976545",
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATION_COMBINED = 2.0  # Maximum duration\n",
    "MAX_SPIKES_COMBINED = 50000  # Maximum spikes\n",
    "\n",
    "print(f\"Monitoring with dual constraints:\")\n",
    "print(f\"  - Duration limit: {DURATION_COMBINED} seconds\")\n",
    "print(f\"  - Spike limit: {MAX_SPIKES_COMBINED:,} spikes\")\n",
    "print(\"Will stop when EITHER limit is reached...\")\n",
    "\n",
    "# Monitor with both constraints\n",
    "spikes_combined = okaer.monitor(\n",
    "    inputs=INPUTS, \n",
    "    max_spikes=MAX_SPIKES_COMBINED, \n",
    "    duration=DURATION_COMBINED\n",
    ")\n",
    "\n",
    "if spikes_combined is None:\n",
    "    okaer.logger.error(\"No spikes were recorded.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MONITORING RESULTS (Combined constraints)\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(MAX_INPUTS):\n",
    "        num_spikes = spikes_combined[i].get_num_spikes()\n",
    "        print(f\"Input {i}: {num_spikes:,} spikes\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36121561",
   "metadata": {},
   "source": [
    "## 5. Visualize Spike Data\n",
    "\n",
    "Now let's create visualizations using the captured spike data. We'll use **pyNAVIS** to generate four types of plots that help us understand the NAS response.\n",
    "\n",
    "First, we create `SpikesFile` objects for all inputs that recorded spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19495607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pyNAVIS SpikesFile objects for inputs with recorded spikes\n",
    "okaer.logger.info(\"Creating spike files for visualization\")\n",
    "spike_files = []\n",
    "\n",
    "for i in range(MAX_INPUTS):\n",
    "    if spikes[i].get_num_spikes() > 0:\n",
    "        spike_files.append(\n",
    "            SpikesFile(\n",
    "                addresses=spikes[i].addresses, \n",
    "                timestamps=spikes[i].timestamps\n",
    "            )\n",
    "        )\n",
    "        print(f\"✓ SpikesFile created for input {i}\")\n",
    "\n",
    "print(f\"\\nTotal spike files created: {len(spike_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66723a25",
   "metadata": {},
   "source": [
    "### 5.1 Spikegram (Raster Plot)\n",
    "\n",
    "The **spikegram** (also called raster plot) displays individual spike events as dots. Each row represents one of the 64 frequency channels, and each dot represents a spike event at a specific time.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Horizontal axis**: Time progression\n",
    "- **Vertical axis**: Frequency channel (0-63, high to low frequency)\n",
    "- **Each dot**: A single spike event\n",
    "- **Patterns**: Horizontal lines indicate sustained activity in specific frequency bands\n",
    "- **Density**: More dots = higher neural activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spikegram for all inputs\n",
    "for i in range(len(spike_files)):\n",
    "    okaer.logger.info(f\"Plotting spikegram for input {INPUTS[i]}\")\n",
    "    Plots.spikegram(spike_files[i], settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c6acf",
   "metadata": {},
   "source": [
    "### 5.2 Sonogram (Frequency-Time Representation)\n",
    "\n",
    "The **sonogram** provides a heat map view of spike activity, showing energy distribution across frequency channels over time.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Horizontal axis**: Time progression\n",
    "- **Vertical axis**: Frequency channel (cochlear position)\n",
    "- **Color intensity**: Amount of spike activity (bright = high activity)\n",
    "- **Patterns**: Bright regions indicate strong acoustic energy at those frequencies\n",
    "- **Temporal evolution**: Shows how frequency content changes over time\n",
    "\n",
    "This visualization is similar to a traditional spectrogram but based on neuromorphic spike events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54662da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sonogram for all inputs\n",
    "for i in range(len(spike_files)):\n",
    "    okaer.logger.info(f\"Plotting sonogram for input {INPUTS[i]}\")\n",
    "    Plots.sonogram(spike_files[i], settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1cdff",
   "metadata": {},
   "source": [
    "### 5.3 Histogram (Spike Count Distribution)\n",
    "\n",
    "The **histogram** shows the total number of spikes per frequency channel across the entire recording period.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Horizontal axis**: Frequency channel number (0-63)\n",
    "- **Vertical axis**: Total spike count\n",
    "- **Height of bars**: Indicates which channels were most active\n",
    "- **Distribution shape**: Reveals the spectral content of the audio signal\n",
    "- **Peaks**: Channels with highest activity correspond to dominant frequencies in the input\n",
    "\n",
    "This plot helps identify which frequency ranges are most important in the input signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b752f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate histogram for all inputs\n",
    "for i in range(len(spike_files)):\n",
    "    okaer.logger.info(f\"Plotting histogram for input {INPUTS[i]}\")\n",
    "    Plots.histogram(spike_files[i], settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767ea5b",
   "metadata": {},
   "source": [
    "### 5.4 Average Activity (Temporal Firing Rate)\n",
    "\n",
    "The **average activity** plot shows how the mean firing rate across all channels evolves over time.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Horizontal axis**: Time progression\n",
    "- **Vertical axis**: Average spike rate (spikes per time bin)\n",
    "- **Curve height**: Overall level of neural activity\n",
    "- **Peaks**: Moments when the NAS is responding strongly to the input\n",
    "- **Temporal dynamics**: Shows onset, sustained activity, and offset of the response\n",
    "\n",
    "This visualization is useful for detecting transient events and understanding the temporal structure of the auditory input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate average activity plot for all inputs\n",
    "for i in range(len(spike_files)):\n",
    "    okaer.logger.info(f\"Plotting average activity for input {INPUTS[i]}\")\n",
    "    Plots.average_activity(spike_files[i], settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a0926",
   "metadata": {},
   "source": [
    "## 6. Process and Analyze Captured Events - Peak Activity Detection\n",
    "\n",
    "Beyond visualization, we can perform computational analysis on the spike data. Let's implement an algorithm to **detect temporal windows with peak activity**.\n",
    "\n",
    "This analysis identifies the time period(s) when the NAS is most active, which could correspond to important acoustic events like speech onset, musical notes, or transient sounds.\n",
    "\n",
    "### Algorithm Overview:\n",
    "\n",
    "1. Define a sliding time window (e.g., 50 milliseconds)\n",
    "2. Slide this window across the recording\n",
    "3. Count spikes in each window position\n",
    "4. Identify the window with maximum activity\n",
    "5. Analyze the channel distribution during that peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a179bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_peak_activity_window(spike_file, window_size_ms=50, settings=None):\n",
    "    \"\"\"\n",
    "    Detect the temporal window with highest spike activity.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spike_file : SpikesFile\n",
    "        PyNAVIS spike file object\n",
    "    window_size_ms : float\n",
    "        Size of sliding window in milliseconds\n",
    "    settings : MainSettings\n",
    "        PyNAVIS settings for timestamp conversion\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing peak window information\n",
    "    \"\"\"\n",
    "    timestamps = spike_file.timestamps\n",
    "    addresses = spike_file.addresses\n",
    "    \n",
    "    if len(timestamps) == 0:\n",
    "        print(\"No spikes to analyze!\")\n",
    "        return None\n",
    "    \n",
    "    # Convert window size to timestamp units\n",
    "    ts_tick = settings.ts_tick if settings else 0.01  # default 0.01 ms\n",
    "    window_size = window_size_ms / ts_tick\n",
    "    \n",
    "    # Get time range\n",
    "    t_min = timestamps.min()\n",
    "    t_max = timestamps.max()\n",
    "    total_duration = t_max - t_min\n",
    "    \n",
    "    # Create sliding windows\n",
    "    window_step = window_size / 4  # 75% overlap for smooth detection\n",
    "    num_windows = int((total_duration - window_size) / window_step) + 1\n",
    "    \n",
    "    print(f\"\\nAnalyzing spike activity...\")\n",
    "    print(f\"  - Total spikes: {len(timestamps):,}\")\n",
    "    print(f\"  - Recording duration: {total_duration * ts_tick:.2f} ms\")\n",
    "    print(f\"  - Window size: {window_size_ms} ms\")\n",
    "    print(f\"  - Number of windows: {num_windows}\")\n",
    "    \n",
    "    # Count spikes in each window\n",
    "    spike_counts = []\n",
    "    window_starts = []\n",
    "    \n",
    "    for i in range(num_windows):\n",
    "        window_start = t_min + i * window_step\n",
    "        window_end = window_start + window_size\n",
    "        \n",
    "        # Count spikes in this window\n",
    "        spikes_in_window = np.sum((timestamps >= window_start) & (timestamps < window_end))\n",
    "        spike_counts.append(spikes_in_window)\n",
    "        window_starts.append(window_start)\n",
    "    \n",
    "    spike_counts = np.array(spike_counts)\n",
    "    window_starts = np.array(window_starts)\n",
    "    \n",
    "    # Find peak window\n",
    "    peak_idx = np.argmax(spike_counts)\n",
    "    peak_start = window_starts[peak_idx]\n",
    "    peak_end = peak_start + window_size\n",
    "    peak_count = spike_counts[peak_idx]\n",
    "    \n",
    "    # Get spikes and channels in peak window\n",
    "    peak_mask = (timestamps >= peak_start) & (timestamps < peak_end)\n",
    "    peak_addresses = addresses[peak_mask]\n",
    "    peak_timestamps = timestamps[peak_mask]\n",
    "    \n",
    "    # Analyze channel distribution in peak window\n",
    "    channel_counts = np.bincount(peak_addresses, minlength=64)\n",
    "    most_active_channels = np.argsort(channel_counts)[-5:][::-1]  # Top 5 channels\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PEAK ACTIVITY WINDOW DETECTED\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Start time: {peak_start * ts_tick:.2f} ms\")\n",
    "    print(f\"  End time: {peak_end * ts_tick:.2f} ms\")\n",
    "    print(f\"  Spikes in window: {peak_count:,}\")\n",
    "    print(f\"  Spike rate: {peak_count / window_size_ms * 1000:.1f} spikes/second\")\n",
    "    print(f\"\\n  Top 5 most active channels during peak:\")\n",
    "    for rank, ch in enumerate(most_active_channels, 1):\n",
    "        print(f\"    {rank}. Channel {ch}: {channel_counts[ch]} spikes\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Plot 1: Spike rate over time with peak highlighted\n",
    "    ax1 = axes[0]\n",
    "    time_axis = window_starts * ts_tick\n",
    "    ax1.plot(time_axis, spike_counts, 'b-', linewidth=1.5, label='Spike count per window')\n",
    "    ax1.axvspan(peak_start * ts_tick, peak_end * ts_tick, alpha=0.3, color='red', \n",
    "                label=f'Peak window ({peak_count} spikes)')\n",
    "    ax1.axhline(y=np.mean(spike_counts), color='gray', linestyle='--', alpha=0.5, label='Mean activity')\n",
    "    ax1.set_xlabel('Time (ms)', fontsize=12)\n",
    "    ax1.set_ylabel('Spike Count', fontsize=12)\n",
    "    ax1.set_title('Temporal Activity Profile with Peak Detection', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Channel distribution during peak window\n",
    "    ax2 = axes[1]\n",
    "    ax2.bar(range(64), channel_counts, color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "    ax2.bar(most_active_channels, channel_counts[most_active_channels], \n",
    "            color='red', edgecolor='black', linewidth=0.5, label='Top 5 channels')\n",
    "    ax2.set_xlabel('Frequency Channel', fontsize=12)\n",
    "    ax2.set_ylabel('Spike Count in Peak Window', fontsize=12)\n",
    "    ax2.set_title('Frequency Distribution During Peak Activity', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlim(-1, 64)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'peak_start': peak_start * ts_tick,\n",
    "        'peak_end': peak_end * ts_tick,\n",
    "        'peak_count': peak_count,\n",
    "        'most_active_channels': most_active_channels,\n",
    "        'channel_counts': channel_counts,\n",
    "        'all_window_counts': spike_counts,\n",
    "        'window_times': window_starts * ts_tick\n",
    "    }\n",
    "\n",
    "# Run peak detection analysis on the first spike file\n",
    "if len(spike_files) > 0:\n",
    "    peak_info = detect_peak_activity_window(spike_files[0], window_size_ms=50, settings=settings)\n",
    "else:\n",
    "    print(\"No spike data available for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8a79f",
   "metadata": {},
   "source": [
    "## 7. Process and Analyze Captured Events - Channel Response Analysis\n",
    "\n",
    "Another important analysis is understanding **which frequency channels respond most strongly** to the input. This reveals the spectral characteristics of the audio signal from a neuromorphic perspective.\n",
    "\n",
    "This analysis helps answer questions like:\n",
    "- Which frequency bands are most prominent in the signal?\n",
    "- Is the response broadband or narrowband?\n",
    "- Are there distinct spectral peaks corresponding to specific sound features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa89647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_channel_response(spike_file, settings=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Analyze and visualize per-channel response characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spike_file : SpikesFile\n",
    "        PyNAVIS spike file object\n",
    "    settings : MainSettings\n",
    "        PyNAVIS settings\n",
    "    top_n : int\n",
    "        Number of top channels to highlight\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing channel response metrics\n",
    "    \"\"\"\n",
    "    timestamps = spike_file.timestamps\n",
    "    addresses = spike_file.addresses\n",
    "    \n",
    "    if len(timestamps) == 0:\n",
    "        print(\"No spikes to analyze!\")\n",
    "        return None\n",
    "    \n",
    "    ts_tick = settings.ts_tick if settings else 0.01\n",
    "    total_duration_ms = (timestamps.max() - timestamps.min()) * ts_tick\n",
    "    total_duration_s = total_duration_ms / 1000.0\n",
    "    \n",
    "    # Calculate per-channel statistics\n",
    "    channel_spike_counts = np.bincount(addresses, minlength=64)\n",
    "    channel_spike_rates = channel_spike_counts / total_duration_s  # spikes per second\n",
    "    \n",
    "    # Identify most responsive channels\n",
    "    top_channels = np.argsort(channel_spike_rates)[-top_n:][::-1]\n",
    "    \n",
    "    # Calculate response concentration\n",
    "    total_spikes = len(addresses)\n",
    "    top_10_spikes = channel_spike_counts[top_channels[:10]].sum()\n",
    "    concentration_ratio = top_10_spikes / total_spikes * 100\n",
    "    \n",
    "    # Calculate spectral spread\n",
    "    weighted_mean = np.average(range(64), weights=channel_spike_counts)\n",
    "    spectral_std = np.sqrt(np.average((np.arange(64) - weighted_mean)**2, weights=channel_spike_counts))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CHANNEL RESPONSE ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Total duration: {total_duration_s:.3f} seconds\")\n",
    "    print(f\"  Total spikes: {total_spikes:,}\")\n",
    "    print(f\"  Active channels: {np.sum(channel_spike_counts > 0)}/64\")\n",
    "    print(f\"\\n  Response concentration: {concentration_ratio:.1f}% in top 10 channels\")\n",
    "    print(f\"  Spectral centroid: Channel {weighted_mean:.1f}\")\n",
    "    print(f\"  Spectral spread: {spectral_std:.1f} channels\")\n",
    "    print(f\"\\n  Top {top_n} most responsive channels:\")\n",
    "    for rank, ch in enumerate(top_channels, 1):\n",
    "        rate = channel_spike_rates[ch]\n",
    "        count = channel_spike_counts[ch]\n",
    "        percentage = count / total_spikes * 100\n",
    "        print(f\"    {rank:2d}. Channel {ch:2d}: {rate:7.1f} spikes/s ({count:6,} spikes, {percentage:5.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Spike rate per channel (bar chart)\n",
    "    ax1 = axes[0, 0]\n",
    "    colors = ['red' if ch in top_channels else 'steelblue' for ch in range(64)]\n",
    "    ax1.bar(range(64), channel_spike_rates, color=colors, edgecolor='black', linewidth=0.5)\n",
    "    ax1.set_xlabel('Frequency Channel (High → Low)', fontsize=11)\n",
    "    ax1.set_ylabel('Spike Rate (spikes/second)', fontsize=11)\n",
    "    ax1.set_title('Channel Response Profile', fontsize=13, fontweight='bold')\n",
    "    ax1.set_xlim(-1, 64)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Cumulative response\n",
    "    ax2 = axes[0, 1]\n",
    "    sorted_rates = np.sort(channel_spike_rates)[::-1]\n",
    "    cumulative_percent = np.cumsum(sorted_rates) / np.sum(sorted_rates) * 100\n",
    "    ax2.plot(range(1, 65), cumulative_percent, 'b-', linewidth=2)\n",
    "    ax2.axhline(y=80, color='red', linestyle='--', alpha=0.5, label='80% threshold')\n",
    "    ax2.axhline(y=50, color='orange', linestyle='--', alpha=0.5, label='50% threshold')\n",
    "    ax2.set_xlabel('Number of Top Channels', fontsize=11)\n",
    "    ax2.set_ylabel('Cumulative Response (%)', fontsize=11)\n",
    "    ax2.set_title('Cumulative Response Distribution', fontsize=13, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(0, 64)\n",
    "    ax2.set_ylim(0, 105)\n",
    "    \n",
    "    # Plot 3: Spike count distribution (log scale)\n",
    "    ax3 = axes[1, 0]\n",
    "    non_zero_counts = channel_spike_counts[channel_spike_counts > 0]\n",
    "    ax3.hist(non_zero_counts, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    ax3.set_xlabel('Spike Count', fontsize=11)\n",
    "    ax3.set_ylabel('Number of Channels', fontsize=11)\n",
    "    ax3.set_title('Distribution of Channel Activity Levels', fontsize=13, fontweight='bold')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Frequency response heatmap view\n",
    "    ax4 = axes[1, 1]\n",
    "    # Reshape into matrix for better visualization\n",
    "    response_matrix = channel_spike_rates.reshape(8, 8)\n",
    "    im = ax4.imshow(response_matrix, cmap='hot', aspect='auto', interpolation='nearest')\n",
    "    ax4.set_xlabel('Channel Group (×8)', fontsize=11)\n",
    "    ax4.set_ylabel('Channel Subgroup', fontsize=11)\n",
    "    ax4.set_title('Response Intensity Heatmap', fontsize=13, fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax4, label='Spike Rate (spikes/s)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'channel_spike_counts': channel_spike_counts,\n",
    "        'channel_spike_rates': channel_spike_rates,\n",
    "        'top_channels': top_channels,\n",
    "        'spectral_centroid': weighted_mean,\n",
    "        'spectral_spread': spectral_std,\n",
    "        'concentration_ratio': concentration_ratio\n",
    "    }\n",
    "\n",
    "# Run channel response analysis\n",
    "if len(spike_files) > 0:\n",
    "    channel_info = analyze_channel_response(spike_files[0], settings=settings, top_n=10)\n",
    "else:\n",
    "    print(\"No spike data available for analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a8696",
   "metadata": {},
   "source": [
    "## 8. Exercise 1: Custom Monitoring Duration\n",
    "\n",
    "**Objective:** Understand how monitoring duration affects data capture and analysis quality.\n",
    "\n",
    "**Task:**  \n",
    "Modify the monitoring parameters to capture events for different durations:\n",
    "- Short duration: 0.1 seconds\n",
    "- Medium duration: 1.0 seconds  \n",
    "- Long duration: 2.0 seconds\n",
    "\n",
    "For each duration:\n",
    "1. Capture the spike data\n",
    "2. Generate the four visualization types (spikegram, sonogram, histogram, average activity)\n",
    "3. Compare the results and answer these questions:\n",
    "   - How does the spike count scale with duration?\n",
    "   - Which visualizations are most affected by shorter durations?\n",
    "   - At what duration do you get a stable representation of the audio signal?\n",
    "\n",
    "**Hint:** You only need to change the `DURATION` variable and re-run the monitoring section. All the plotting code can remain the same.\n",
    "\n",
    "**Expected observations:**\n",
    "- Shorter durations may miss transient events\n",
    "- Longer durations provide more stable statistics but require more memory\n",
    "- The histogram should stabilize as duration increases\n",
    "- The sonogram quality improves with longer captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3623d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Try different monitoring durations\n",
    "# TODO: Modify DURATION and run the monitoring + visualization cells\n",
    "\n",
    "# Example code structure:\n",
    "# DURATION = 0.1  # Try: 0.1, 1.0, 2.0 seconds\n",
    "# spikes = okaer.monitor(inputs=INPUTS, duration=DURATION)\n",
    "# ... create spike_files ...\n",
    "# ... generate plots ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Experiment with different DURATION values and observe the differences\n",
    "\n",
    "print(\"Exercise 1: Experiment with monitoring durations\")\n",
    "print(\"Suggested durations to try: 0.1s, 1.0s, 2.0s\")\n",
    "print(\"Observe how the visualizations change with duration\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
